{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new word \"saw\"\n",
      "new word \"coast\"\n",
      "new word \"might\"\n",
      "new word \"hangzhou\"\n",
      "new word \"huge\"\n",
      "new word \"wasn\"\n",
      "new word \"but\"\n",
      "new word \"glimpse\"\n",
      "new word \"inside\"\n",
      "new word \"china\"\n",
      "new word \"pavilion\"\n",
      "new word \"expo\"\n",
      "new word \"pretty\"\n",
      "new word \"each\"\n",
      "new word \"province\"\n",
      "new word \"exhibit\"\n",
      "new word \"hommies\"\n",
      "new word \"call\"\n",
      "new word \"roofer\"\n",
      "new word \"spaying\"\n",
      "new word \"foaming\"\n",
      "new word \"dusty\"\n",
      "new word \"pls\"\n",
      "new word \"close\"\n",
      "new word \"doors\"\n",
      "new word \"help\"\n",
      "new word \"close\"\n",
      "new word \"bathroom\"\n",
      "new word \"window\"\n",
      "new word \"cat\"\n",
      "new word \"window\"\n",
      "new word \"sliding\"\n",
      "new word \"behind\"\n",
      "new word \"cats\"\n",
      "new word \"survive\"\n",
      "new word \"sorry\"\n",
      "new word \"any\"\n",
      "new word \"inconvenience\"\n",
      "new word \"scifinance\"\n",
      "new word \"automatically\"\n",
      "new word \"generates\"\n",
      "new word \"gpu\"\n",
      "new word \"enabled\"\n",
      "new word \"pricing\"\n",
      "new word \"risk\"\n",
      "new word \"model\"\n",
      "new word \"source\"\n",
      "new word \"code\"\n",
      "new word \"runs\"\n",
      "new word \"300x\"\n",
      "new word \"faster\"\n",
      "new word \"than\"\n",
      "new word \"serial\"\n",
      "new word \"code\"\n",
      "new word \"nvidia\"\n",
      "new word \"fermi\"\n",
      "new word \"class\"\n",
      "new word \"tesla\"\n",
      "new word \"series\"\n",
      "new word \"gpu\"\n",
      "new word \"scifinance\"\n",
      "new word \"derivatives\"\n",
      "new word \"pricing\"\n",
      "new word \"risk\"\n",
      "new word \"model\"\n",
      "new word \"development\"\n",
      "new word \"tool\"\n",
      "new word \"automatically\"\n",
      "new word \"generates\"\n",
      "new word \"gpu\"\n",
      "new word \"enabled\"\n",
      "new word \"source\"\n",
      "new word \"code\"\n",
      "new word \"concise\"\n",
      "new word \"high\"\n",
      "new word \"level\"\n",
      "new word \"model\"\n",
      "new word \"specifications\"\n",
      "new word \"parallel\"\n",
      "new word \"computing\"\n",
      "new word \"cuda\"\n",
      "new word \"programming\"\n",
      "new word \"expertise\"\n",
      "new word \"scifinance\"\n",
      "new word \"automatic\"\n",
      "new word \"gpu\"\n",
      "new word \"enabled\"\n",
      "new word \"monte\"\n",
      "new word \"carlo\"\n",
      "new word \"pricing\"\n",
      "new word \"model\"\n",
      "new word \"source\"\n",
      "new word \"code\"\n",
      "new word \"generation\"\n",
      "new word \"capabilities\"\n",
      "new word \"significantly\"\n",
      "new word \"latest\"\n",
      "new word \"release\"\n",
      "new word \"includes\"\n",
      "new word \"latest\"\n",
      "new word \"biggerpenis\"\n",
      "new word \"grow\"\n",
      "new word \"safest\"\n",
      "new word \"effective\"\n",
      "new word \"methods\"\n",
      "new word \"of_penisen1argement\"\n",
      "new word \"money\"\n",
      "new word \"bettererections\"\n",
      "new word \"effective\"\n",
      "new word \"ma1eenhancement\"\n",
      "new word \"ma1eenhancement\"\n",
      "new word \"supplement\"\n",
      "new word \"trusted\"\n",
      "new word \"millions\"\n",
      "new word \"retirement\"\n",
      "new word \"party\"\n",
      "new word \"leaves\"\n",
      "new word \"changing\"\n",
      "new word \"color\"\n",
      "naive bayes classfication\n",
      "acc 0.9\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -*- encoding:utf-8 -*-\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "\"\"\"\n",
    "@2016-6-16 10:53:57\n",
    "朴素贝叶斯分类器，进行文本分类\n",
    "注意本次实现针对的是垃圾邮件的过滤\n",
    "在测试时计算的不是真正的后验概率，仅计算出现的词，在两类别下条件概率的乘积，姑且叫做准后验概率\n",
    "采用的拉普拉斯平滑，并且对准后验取了对数\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "numpy使用bool索引时，注意不要使用mat条件判断\n",
    "\"\"\"\n",
    "class NaiveBayes(object):\n",
    "    def __init__(self):\n",
    "        print 'naive bayes classfication'\n",
    "    \n",
    "    def train(self,X,Y):\n",
    "        \"\"\"输入二维列表X和列表Y\"\"\"\n",
    "        XMat=np.mat(X)\n",
    "        Y=np.array(Y)\n",
    "        X1Mat=XMat[Y==1]\n",
    "        #print X1Mat.shape\n",
    "        X0Mat=XMat[Y==0]\n",
    "        #print X0Mat.shape\n",
    "        X0Num=np.sum(Y==0)\n",
    "        X1Num=np.sum(Y==1)\n",
    "        P0 = (np.sum(X0Mat,axis=0)+1)/(np.float64(X0Num)+2)\n",
    "        P1=(np.sum(X1Mat,axis=0)+1)/(np.float64(X1Num)+2)\n",
    "        #print P1.shape\n",
    "        self.P0=P0\n",
    "        self.P1=P1\n",
    "        self.pclass1=X1Num/np.float64(X0Num+X1Num)\n",
    "        return P0,P1,X1Num/np.float64(X0Num+X1Num)\n",
    "    \n",
    "    def test(self,X,Y):\n",
    "        XMat=np.mat(X)\n",
    "        Y=np.array(Y)\n",
    "        predict1= XMat*self.P1.T+math.log(self.pclass1)\n",
    "        predict0= XMat*self.P0.T +math.log(1-self.pclass1)\n",
    "        predict= np.ones(Y.shape[0])\n",
    "        predict0=np.array(predict0.T)\n",
    "        predict1=np.array(predict1.T)\n",
    "        predict[predict0[0,:]>predict1[0,:]]=0\n",
    "        print 'acc',np.sum(predict==Y)/np.float64(Y.shape[0])\n",
    "        \n",
    "        \n",
    "\n",
    "def textParse(bigString):\n",
    "    import re\n",
    "    listofToken=re.split(r'\\W*',bigString)\n",
    "    return [tok.lower() for tok in listofToken if len(tok)>2 ]\n",
    "        \n",
    "def createVocabList(dataSet):\n",
    "    \"\"\"\n",
    "    产生词典\n",
    "    \"\"\"\n",
    "    vocabSet = set([])\n",
    "    for doc in dataSet:\n",
    "        vocabSet = vocabSet | set(doc)\n",
    "    return list(vocabSet)\n",
    "\n",
    "def wordbag2Vec(vocabList,inputSet):\n",
    "    \"\"\"输入词典list 输入一个文档list 输出一个向量 (0,1 组成）\"\"\"\n",
    "    retVec = [0]*len(vocabList)\n",
    "    for word in inputSet:\n",
    "        if word in vocabList:\n",
    "            retVec[vocabList.index(word)]=1\n",
    "        else:\n",
    "            print 'new word \"%s\"'% word\n",
    "    return retVec\n",
    "    \n",
    "\n",
    "    \n",
    "def prepare_data():\n",
    "    import codecs\n",
    "    docList=[]\n",
    "    classList=[]\n",
    "    allTerm=[]\n",
    "    for i in range(1,26):\n",
    "        termList = textParse(codecs.open('email/spam/%d.txt'%i).read())\n",
    "        docList.append(termList)\n",
    "        allTerm.extend(termList)\n",
    "        classList.append(1)\n",
    "        termList = textParse(codecs.open('email/ham/%d.txt'%i).read())\n",
    "        docList.append(termList)\n",
    "        allTerm.extend(termList)\n",
    "        classList.append(0)\n",
    "    train = 40\n",
    "    trainMat=[]\n",
    "    labelMat=[]\n",
    "    testMat=[]\n",
    "    testlabelMat=[]\n",
    "    vocabList= createVocabList(docList[0:train])\n",
    "    for i in range(train):\n",
    "        trainMat.append(wordbag2Vec(vocabList,docList[i]))\n",
    "        labelMat.append(classList[i])\n",
    "    for i in range(train,50):\n",
    "        testMat.append(wordbag2Vec(vocabList,docList[i]))\n",
    "        testlabelMat.append(classList[i])\n",
    "    return trainMat,labelMat,testMat,testlabelMat\n",
    "                \n",
    "X,Y,test_X,test_Y=prepare_data()\n",
    "NB=NaiveBayes()\n",
    "NB.train(X,Y)\n",
    "NB.test(test_X,test_Y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 5 6]]\n"
     ]
    }
   ],
   "source": [
    "a=[[1,2,3],[4,5,6]]\n",
    "b=np.mat(a)\n",
    "c=np.array([1,0])\n",
    "print b[c==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a', 'b', 'c'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=['a','a','b','c']\n",
    "set(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
